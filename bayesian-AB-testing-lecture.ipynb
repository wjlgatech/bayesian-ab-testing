{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Bayesian A/B Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The story of your future-self ...**\n",
    "\n",
    "Imagine that 6 months down to the load you start interviewing a unicorn eCommerce company `AMAZING` for a product data scientist position. Here is an open-end question you are asked: \n",
    "\n",
    "The company wants to launch a new feature in order to improve the conversion rate of their website visitors. \n",
    "\n",
    "- What will you do to test whether the new feature working or not?\n",
    "\n",
    "- What metrics are you going use to evaluate the performance of the new feature?\n",
    "\n",
    "- To what extend that the new feature is better than the old one?\n",
    "\n",
    "- In case that company is limited by budget (i.e. time, money, people), how soon can you provide some useful results? such as whether the new feature works or not? by how much (better than the old one)?\n",
    "\n",
    "![](images/ecom-ab-testing.png)\n",
    "[source](https://howuku.com/blog/what-is-conversion-rate-optimization/)\n",
    "\n",
    "**Objectives**\n",
    "\n",
    "You can count today a success if you can... \n",
    "\n",
    "- Compare and Contrast Frequentist vs Bayesian Mindsets for A/B testing\n",
    "- Perform A/B Testing under a Bayesian Framework\n",
    "- Explain what a conjugate prior is\n",
    "- Explain why Bayesian A/B Testing is _Bayesian_\n",
    "\n",
    "**Road-map**\n",
    "\n",
    "1. Review Frequentist Hypothesis Testing\n",
    "2. Introduce Beta Distribution\n",
    "3. How to use Beta Distribution\n",
    "4. Actually do the original A/B test\n",
    "5. Answer the question... What's the probability that site B is better than site A?\n",
    "6. Answer Why do we call this Bayesian A/B Testing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import *\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Review of Frequentist Hypothesis Testing\n",
    "\n",
    "Steps:\n",
    "\n",
    "1. Define your null hypothesis.\n",
    "2. Define the alpha (significance) cutoff.\n",
    "3. Determine how many samples you'll need for a given effect size and significance level (the power).\n",
    "3. Collect data.\n",
    "4. Compute the appropriate statistic (e.g. the t-statistic).\n",
    "5. Compute the probability of that statistic (or something more rare) under the null hypothesis. (aka, the p-value)\n",
    "6. \"Reject\" or \"fail to reject\" the null hypothesis.\n",
    "\n",
    "For example,\n",
    "\n",
    "Say our company goal is to have our website generate new users with a conversion rate of 10%. Let's do a hypothesis test to see if we are hitting our goal.\n",
    "\n",
    "**Step 1:**\n",
    "\n",
    "Define the null hypothesis as \"the conversion rate is 10%\", i.e. $\\mu = 0.1$  Alternate, \"the conversion rate is not 10%\" $\\mu \\ne 0.1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_hypot_mu = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2:**\n",
    "\n",
    "Define the significance level (alpha cutoff). We'll use the typical 5% type-I error rate, and choose a two-tailed test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_cutoff = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3:**\n",
    "\n",
    "The data is a series of bernoulli trials (a binomial distribution)- either a person converts or they don't.  The Null hypothesis is the proportion that convert, p, is 0.1, of 1 in 10.  \n",
    "\n",
    "Need a power calculation for 2-sided one-sample binomial test.\n",
    "\n",
    "Oh look.  [Here](http://powerandsamplesize.com/Calculators/Other/1-Sample-Binomial) is a one-sample binomial test power calculator.  Let's use it with an effect size of 1% (0.01)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from the calculator\n",
    "n = 7670"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4:**\n",
    "\n",
    "Collect data. Here it is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = 1*(np.random.random(n)>1 - .11)\n",
    "print('A few results: ', samples)\n",
    "print('Conversions: ',samples.sum())\n",
    "print('Non-conversions: ', len(samples)-samples.sum())\n",
    "print('Conversion rate: ', samples.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 5 and 6:**  \n",
    " \n",
    "The [binomial test](https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.stats.binom_test.html) tests whether a proportion (such as the mean number of clicks) is equal to some value.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import binom_test\n",
    "\n",
    "successes = samples.sum()\n",
    "trials = len(samples)\n",
    "\n",
    "p_value = stats.binom_test(successes, trials, null_hypot_mu)\n",
    "\n",
    "print('p value: ', p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Concept of P-value\n",
    "\n",
    ">The probability of observing data at least as extreme as the observation given the null hypothesis\n",
    "\n",
    "> Because the null hypothesis is all about 'nothing different, no change'. If you stick to your routine and boring assumption called null hypothesis, how shocking you will feel when you see such rare evidence happens. The smaller the probability of the evidence, the more shocking you feel. --Paul.Wu\n",
    "\n",
    "#### What's wrong with the traditional hypothesis testing?\n",
    "\n",
    "Say our company is rolling out an A/B test to determine if the new \"Click to Shop\" Button is improving our clickthrough rates? \n",
    "\n",
    "You go through all the steps a frequentist would and find a p_value lower than your original alpha value. You head to the stakeholders meeting and say... \n",
    "\n",
    "    \"Assuming that our new button is not better than our original, I feel confident that would not see this data (or something more rare) if I sampled from this site over-and-over-and-over... forever. so we can claim that we have a higher CTR using our new button. - nothing is ever certain but we are happily confident that our Null Hypothesis can be rejected.\"  \n",
    "\n",
    "Not only is it a mouthful but wouldn't it be nice to come to your stakeholders with a phrase you can get behind like ... \n",
    "\n",
    "    \"It is 98% likely that site B has a higher CTR than site A\"\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What could be done with the pain-point of frequentist hypothesis testing?\n",
    "\n",
    "Wouldn’t it be nice if, instead, we could give a **distribution of probability**, rather than **yes  or no**, of a ***hypothesis*** given the ***data***?\n",
    "\n",
    "This is where bayesian statistics comes in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Let's do Bayesian A/B Testing\n",
    "\n",
    "So, we know how to run hypothesis tests (from the **frequentist** world), and we can do **A/B testing via hypothesis testing**, of course.\n",
    "\n",
    "But now let's do **A/B testing under a Bayesian framework**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick question1... What do we use to model uncertainty about female heights? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick question2...What do we use to model the uncertainty of a probability? \n",
    "\n",
    "Which distribution do we know that will allow us to say:\n",
    "\n",
    "    \"It is 98% likely that site B has a higher CTR than site A\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it's even better to says: 95 out of 100 times, it is from 97% to 99% likely that site B has a higher CTR than site A."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. The Beta Distribution: $\\text{Beta}(\\alpha, \\beta)$\n",
    "\n",
    "The Beta Distribution is a **probability distribution on probabilities**. In other words, it is used to model probabilities.\n",
    "\n",
    "\n",
    "> First, define p as the probability of landing a head. If the coin is fair, then it is most likely that the coin will land head half of the time. In this case, p = 50% is the most likely value for p. But wait, it is also possible to have an unfair coin that behaves accidentally like a fair coin. So we cannot rule out the possibility that the coin is unfair, even if we observe heads half of the time.\n",
    "\n",
    "##### For example:\n",
    "\n",
    "Assume that $Prob(Head)=p$. If you want to determine whether or not you are flipping a fair or unfair coin, then you can use the Beta Distribution to fit your data of flipping. The resulting $p$ will take on any value between 0 and 1.\n",
    "\n",
    "##### Parameters\n",
    "\n",
    "The beta distribution has two hyper-parameters (also known as \"shape parameters\"):\n",
    "- $\\alpha > 0$: we will use this to encode the number of `successes` of a website (more on that later)\n",
    "- $\\beta > 0$: we will use this to encode the number of `failures` of a website (more on that later)\n",
    "\n",
    "You can choose the $\\alpha$ and $\\beta$ parameters however you think they are supposed to be. For example, if you think the probability of success is very high, let’s say 90%, set 90 for $\\alpha$ and 10 for $\\beta$. Again more on this later...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imagine we get 7 heads and 3 tails... \n",
    "alpha = 7\n",
    "beta = 3\n",
    "\n",
    "dist = stats.beta(alpha, beta)\n",
    "x = np.linspace(0.0, 1.0, 301)\n",
    "\n",
    "# The probability density at each sample support value.\n",
    "y = dist.pdf(x)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "lines = ax.plot(x, y)\n",
    "ax.fill_between(x, y, alpha=0.2, color='red')\n",
    "    \n",
    "ax.set_title('First View of Beta')\n",
    "# ax.get_yaxis().set_ticks([])\n",
    "ax.set_xlabel('All possible values for probability')\n",
    "ax.set_ylabel('Probability Density')\n",
    "dist.cdf(0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hand-on: create a function `plot_beta()` \n",
    "that plots the Beta distribution PDF with given parameters alpha and beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_beta(alpha, beta, ax=None, title=\"\", xlabel=\"\",ylabel=\"\", label=\"\"):\n",
    "    \"\"\"plot the Beta distribution PDF with parameters alpha and beta\n",
    "    Args\n",
    "    ----\n",
    "        alpha (positive number)\n",
    "        beta (positive number)\n",
    "    \"\"\"\n",
    "    # Build a beta distribtuion scipy object.\n",
    "    dist = stats.beta(alpha, beta)\n",
    "\n",
    "    # The support (always this for the beta dist).\n",
    "    x = np.linspace(0.0, 1.0, 301)\n",
    "\n",
    "    # The probability density at each sample support value.\n",
    "    y = dist.pdf(x)\n",
    "\n",
    "    # Plot it all.\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(6,6))\n",
    "    xticks=[0.0, 0.5, 1.0]\n",
    "    lines = ax.plot(x, y, label=label)\n",
    "    ax.fill_between(x, y, alpha=0.2, color=lines[0].get_c())\n",
    "    if title: \n",
    "        ax.set_title(title)\n",
    "    else:\n",
    "        ax.set_title(f'Beta distribution alpha={alpha}, beta={beta} ')\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.get_yaxis().set_ticks([])\n",
    "    #ax.get_yaxis().set_ticks([np.max(y)])\n",
    "    ax.get_xaxis().set_ticks(xticks)\n",
    "    ax.set_ylim(0.0, min(np.max(y)*1.2,100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interactive, FloatSlider, IntSlider, fixed\n",
    "from IPython.display import display, Image\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "        \n",
    "plot=interactive(plot_beta,\n",
    "                 alpha=IntSlider(min=1,max=35,step=1,value=1),\n",
    "                 beta=IntSlider(min=1,max=35,step=1,value=1),\n",
    "                 ax=fixed(None), #fix other arguments\n",
    "                 title=fixed(\"\"), \n",
    "                 xlabel=fixed(\"\"),\n",
    "                 ylabel=fixed(\"\"),\n",
    "                 label=fixed(\"\")\n",
    "                )\n",
    "display(plot)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### The Properties of Beta Distribution (optional)\n",
    "**NOTE: knowing the pdf and ${B(\\alpha, \\beta)}$ piece is not in your success criteria, but if you are interested here is some information about the Distribution.**\n",
    "\n",
    "Support: $x \\in [0, 1]$\n",
    "\n",
    "PDF: $f(x) = \\dfrac{x^{\\alpha - 1} (1-x)^{\\beta - 1}}{B(\\alpha, \\beta)}$\n",
    "\n",
    "where $B(\\alpha, \\beta) = \\dfrac{\\Gamma(\\alpha)\\Gamma(\\beta)}{\\Gamma(\\alpha + \\beta)}$\n",
    "\n",
    "where $\\Gamma(x)$ is an extension of the factorial function which works for a wider range of input (like any positive real value)\n",
    "\n",
    "**Get a feel for the Beta Distribution:**\n",
    "\n",
    "Let's plot a few Beta Distributions (with varying shape parameters)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Note:\n",
    "\n",
    "- A key property of the beta distribution is that it is constrained to the range of 0 to 1. This is different than some other distributions that extend from $-\\infty$ to $+\\infty$ or $0$ to $+\\infty$.\n",
    "\n",
    "- This constraint makes it useful for modeling the $p$ parameter of a bernoulli or binomial distribution, which we know can only take values between 0 and 1.\n",
    "\n",
    "- As we will see in a minute, this correspondence between $\\beta$ and $p$ is more than just superficial. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**What patterns do you see in the above distributions?**\n",
    "\n",
    "Here are a few:\n",
    "* If $\\alpha$ is larger than $\\beta$, the distribution is shifted to the **right** and skewed to the left.\n",
    "* If $\\alpha$ is smaller than $\\beta$, the distribution shifted to the **left** and skewed to the right.\n",
    "* If $\\alpha = \\beta$, the distribution is **symmetric** and **centered** at $0.5$.\n",
    "* The distribution gets **skinnier** as $\\alpha$ and $\\beta$ increase.\n",
    "\n",
    "Linking $\\alpha$ and $\\beta$ to the moments:\n",
    "\n",
    "The **mean** of the Beta Distribution is: $E(X) = \\dfrac{\\alpha}{\\alpha + \\beta}$\n",
    "\n",
    "The **variance** of the Beta Distribution is: $\\text{Var}(X) = \\dfrac{\\alpha \\beta}{(\\alpha + \\beta)^2 (\\alpha + \\beta + 1)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 3. How we can use the Beta Distribution: estimating beta dist. from conversion data\n",
    "\n",
    "What if we set:\n",
    "- $\\alpha = 1 + \\text{number of conversions on our website}$\n",
    "- $\\beta = 1 + \\text{number of misses on our website}$\n",
    "- $\\alpha + \\beta = 2 + \\text{total number of visits to website}$\n",
    "\n",
    "Then, as we know, the **mean of the beta distribution** would be $\\dfrac{\\alpha}{\\alpha + \\beta}$ which equals smoothed **conversion rate**!\n",
    "\n",
    "If we think of $\\alpha$ as \"Wins\" or \"Heads\" and $\\beta$ as \"Losses\" or \"Tails\", then \n",
    "\n",
    "$$\\alpha + \\beta = flips$$\n",
    "\n",
    "and \n",
    "\n",
    "$$\\frac{\\alpha}{\\alpha + \\beta}=\\frac{Heads}{Flips}$$\n",
    "\n",
    "is the probability of heads, which is the $p$ of a bernoulli or binomial distribution.\n",
    "\n",
    "Also, the more visitors we have (i.e. the larger $(\\alpha + \\beta)$), then the **smaller the variance of our beta distribution will be**.\n",
    "\n",
    "Put all this together, **_the beta distribution models the probability of the conversion rate_** of our website (which we are trying to figure out from our data). The beta distribution is one way to model our **belief** of what the conversion rate might be.\n",
    "\n",
    "A continuous probability distribution (like the beta distribution) puts relative likelihoods to each of the values in the support. In our case, the support is theorized conversion rates. On the y-axis of the PDF we have probability density, and on the x-axis of the PDF we have probabilities (all the possible values of conversion rate). So we have probabilities of probabilities (relative probability of conversion rates.)\n",
    "\n",
    "**Why we like it:** The reason we like it is that this lets us know the **strength of our belief** about the conversion rate of our website. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "QUESTION: Are all of these conversion rates the same? \n",
    "\n",
    "$$ \\frac{2}{10} =\\frac{20}{100}=\\frac{200}{1000} $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hand-on: create a function `estimate_beta_params()`:\n",
    "that estimates the alpha & beta parameters of beta distribution by fitting Beta distribution to the conversion data.\n",
    "\n",
    "#### Hand-on: create a function `plot_beta_from_data()`\n",
    "that first estimates the Beta distribution parameters from data and then plots the Beta PDF distribution.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def estimate_beta_params(data):\n",
    "    \"\"\"Estimate the alpha & beta parameters of beta distribution by fitting Beta distribution to the conversion data \n",
    "    Args\n",
    "    ----\n",
    "        data: a list of 0 (miss) or 1 (convert) or a 1-D np.array\n",
    "    return\n",
    "    ------\n",
    "        Alpha: number of successes +1\n",
    "        Beta: Number of failures +1\n",
    "        Mean: conversion rate\n",
    "        num_conversions & total_visitors: used to make labels on graphs \n",
    "    \n",
    "    \"\"\"\n",
    "    #array of website conversions... zeros and ones (convert or didnt convert)\n",
    "    website_samples = np.array(data)\n",
    "    \n",
    "    #total number of conversions\n",
    "    num_conversions = website_samples.sum()\n",
    "    #total number of datapoints\n",
    "    total_visitors = len(website_samples)\n",
    "    \n",
    "    #plus one to set a and beta as uniform priors...try other numbers to see the changes\n",
    "    alpha = num_conversions + 1\n",
    "    beta = (total_visitors - num_conversions) + 1\n",
    "    \n",
    "    #mean number of conversions... aka conversion rate\n",
    "    mean = 1 * num_conversions / total_visitors\n",
    "\n",
    "    return alpha, beta, mean, num_conversions, total_visitors\n",
    "\n",
    "def plot_beta_from_data(data, ax=None, label=None):\n",
    "    \"\"\"First estimate the Beta distribution parameters from data and then plot the Beta PDF distribution\n",
    "    Args\n",
    "    ----\n",
    "        data: a list of 0 (miss) or 1 (convert)\n",
    "    \n",
    "    \"\"\"\n",
    "    alpha, beta, mean, num_conversions, total_visitors = estimate_beta_params(data)\n",
    "    title =  r\"Converted {}/{}\".format(num_conversions, total_visitors)\n",
    "    plot_beta(alpha, beta, ax=ax, title=title, xlabel=\"Conversion Rate\", ylabel=\"Probability Density\", label=label)\n",
    "\n",
    "\n",
    "plot_beta_from_data([0, 1, 0, 0, 0]*1)\n",
    "plot_beta_from_data([0, 1, 0, 0, 0]*10)\n",
    "plot_beta_from_data([0, 1, 0, 0, 0]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[0, 1, 0, 0, 0]*2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What do you find from these three graphs?\n",
    "* $\\frac{2}{10}$ conversion suggests the conversion rate is about $p=0.2$, but values of $p$ in the range of $0.05$ to $0.45$ would not be unreasonable\n",
    "* $\\frac{20}{100}$ also suggests $p=0.2$ and less probability of values of $p$ far from $0.2$\n",
    "* $\\frac{200}{1000}$ indicates $p=0.2$ or some number quite close to $0.2$. No value far from $0.2$ is reasonable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "It is clear that we can use this distribution to model both \n",
    "\n",
    "(1) our belief of the conversion rate based on the data we have (i.e. via the mean), and \n",
    "\n",
    "(2) the strength of our belief (i.e. via the variance).\n",
    "\n",
    "**A good Bayesian never claims to know anything exactly. Instead they have some beliefs, and they have various levels of strengths regarding their beliefs.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 4. Bayesian A/B testing\n",
    "\n",
    "We're finally ready to do the Bayesian A/B testing.\n",
    "\n",
    "Say we have two versions of our website: version A and version B (version C we'll use later).\n",
    "\n",
    "Let's read in the log of our historical visitors for both version A and version B.\n",
    "\n",
    "A .npz file contains saved numpy arrays using [.savez](https://docs.scipy.org/doc/numpy-1.15.0/reference/generated/numpy.savez.html#numpy.savez)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "x = np.load(\"samples.npz\")\n",
    "list(x.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# take a peek at the data\n",
    "x['site_A_samples'][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# how many total?\n",
    "print(\"Shape A: \", x['site_A_samples'].shape)\n",
    "print(\"Shape B: \", x['site_B_samples'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# load in a subset\n",
    "n = 200\n",
    "site_A_samples = x['site_A_samples'][:n]\n",
    "site_B_samples = x['site_B_samples'][:n]\n",
    "\n",
    "np.mean(site_A_samples), np.mean(site_B_samples)\n",
    "\n",
    "#can we stop there and be content that site_B_samples have a higher average?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now let's plot our belief about each site's conversion rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(10, 4))\n",
    "\n",
    "plot_beta_from_data(data=site_A_samples, ax=ax)\n",
    "plot_beta_from_data(data=site_B_samples, ax=ax)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Let's look at how the distributions evolve as data rolls in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hand-on: create a function `compare_AB_conversion_rate()`\n",
    "that compares the conversion rate of 2 different solutions A & B\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def compare_AB_conversion_rate(site_A_data, site_B_data, n=None):\n",
    "    \"\"\"compare the conversion rate of 2 different solutions A & B\n",
    "    Args\n",
    "    ----\n",
    "        site_A_data (1-D np.array of shape (N,))\n",
    "        site_B_data (1-D np.array of shape (N,))\n",
    "        n (int): use a sub list of samples[:n]\n",
    "    Return\n",
    "    ------\n",
    "        a plot comparing the conversion rate of site A and that of site B.\n",
    "    \"\"\"\n",
    "    ax = plt.subplot()\n",
    "    if n is None:\n",
    "        n = min(len(site_A_data), len(site_A_data))\n",
    "    site_A_samples = site_A_data[:n]\n",
    "    site_B_samples = site_B_data[:n]\n",
    "    plot_beta_from_data(site_A_samples, ax, label=\"Site A\")\n",
    "    plot_beta_from_data(site_B_samples, ax, label=\"Site B\")\n",
    "    plt.title(f'after {n} visitors')\n",
    "    plt.show()\n",
    "    \n",
    "interactive(compare_AB_conversion_rate, \n",
    "            n = IntSlider(min=1,max=len(x['site_A_samples']),step=10,value=1),\n",
    "            site_A_data=fixed(x['site_A_samples']), \n",
    "            site_B_data=fixed(x['site_B_samples'])\n",
    "           )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 5. Important question: What's the probability that site B is better than site  A?\n",
    "Let's figure out how much of site B's Beta distribution is to the right of site A's.\n",
    "\n",
    "To do this, all we have to do is to take the integral of this function:\n",
    "\n",
    "$f(x) = \\dfrac{x^{\\alpha - 1} (1-x)^{\\beta - 1}*{\\Gamma(\\alpha)\\Gamma(\\beta)}}{{\\Gamma(\\alpha + \\beta)}}$\n",
    "\n",
    "Where $\\Gamma$ is, of course the well-known gamma function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "As it turns out, this calculation is somewhat difficult, but we can take a shortcut using *Monte Carlo* simulation. This shortcut is widely used among data scientists and data engineers. \n",
    "\n",
    "> When you can not find a theoretical solution for a complex math problem, consider solve it numerically OR by simulation experiment.\n",
    "\n",
    "To be specific, we simply **draw a large number of random samples from each distribution, and count how many times B's samples are greater than A's.**\n",
    "\n",
    "The code is short and easy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "num_simulations = 100_000\n",
    "\n",
    "#Let's just grab our Alpha and betas from site_A\n",
    "alpha, beta = estimate_beta_params(site_A_samples)[:2]\n",
    "print(f'Site_A alpha and beta {alpha, beta}')\n",
    "#Set up first distribution\n",
    "dist_A = stats.beta(alpha, beta)\n",
    "\n",
    "#Same steps for beta dist\n",
    "alpha, beta = estimate_beta_params(site_B_samples)[:2]\n",
    "print(f'Site_B alpha and beta {alpha, beta}')\n",
    "dist_B = stats.beta(alpha, beta)\n",
    "\n",
    "#randomly sample 100_000 data points from each distribution\n",
    "simulated_A = dist_A.rvs(num_simulations)\n",
    "simulated_B = dist_B.rvs(num_simulations)\n",
    "\n",
    "\n",
    "print(f'On average, how many times is Bs Conversion Rate greater than As: {(simulated_B > simulated_A).mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Another way to look at this data is by plotting random samples from B against random samples of A. This creates a 'blob plot'. By measuring how much of the blob is above the *y=x* line, we can determine the probability that B is better than A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#scatter plot our different conversion rates sampled from our distributions\n",
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "ax.scatter(simulated_A, simulated_B, alpha = .2);\n",
    "ax.set_xlim(plt.ylim())\n",
    "ax.set_xlabel('A'), \n",
    "ax.set_ylabel('B')\n",
    "ax.plot(plt.xlim(), plt.xlim(), color = 'blue');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Tips for code re-use**: always put your useful code into function, class etc. and save them in a file (e.g. `utils.py`) that your computer can easily find (e.g. `~/bin`). [Bash Profile](https://github.com/GalvanizeDataScience/primers/blob/master/bash-profile.md)  \n",
    "\n",
    "#### Hand-On: create a function `compare_AB_by_simulations()`\n",
    "\n",
    "- compute the probability that site B is better than site A\n",
    "- create a 'blob plot': plotting random samples from B against random samples of A.  By measuring how much of the blob is above the y=x line, we can determine the probability that B is better than A.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def compare_AB_by_simulations(site_A_samples, site_B_samples, num_simulations = 100_000):\n",
    "    \"\"\" 1) compute the probability site B is better than site A\n",
    "        2) create a 'blob plot': plotting random samples from B against random samples of A.  By measuring how much of the blob is above the y=x line, we can determine the probability that B is better than A.\n",
    "    Args\n",
    "    ----\n",
    "        site_A_samples (1-D np.array) of 0 (miss) and 1 (convert)\n",
    "        site_B_samples (1-D np.array) of 0 (miss) and 1 (convert)\n",
    "    Return\n",
    "    ------\n",
    "        prob_B_betterthan_A: the probability of site B is better than A\n",
    "    \"\"\"\n",
    "\n",
    "    #Let's just grab our Alpha and betas from site_A\n",
    "    alpha_A, beta_A = estimate_beta_params(site_A_samples)[:2]\n",
    "    #print(f'Site_A alpha and beta {alpha, beta}')\n",
    "    #Set up first distribution\n",
    "    dist_A = stats.beta(alpha_A, beta_A)\n",
    "\n",
    "    #Same steps for beta dist\n",
    "    alpha_B, beta_B = estimate_beta_params(site_B_samples)[:2]\n",
    "    #print(f'Site_B alpha and beta {alpha, beta}')\n",
    "    dist_B = stats.beta(alpha_B, beta_B)\n",
    "\n",
    "    #randomly sample 100_000 data points from each distribution\n",
    "    simulated_A = dist_A.rvs(num_simulations)\n",
    "    simulated_B = dist_B.rvs(num_simulations)\n",
    "    prob_B_betterthan_A = (simulated_B > simulated_A).mean()\n",
    "\n",
    "    #print(f'On average, how many times is Bs Conversion Rate greater than As: {prob_B_betterthan_A}')\n",
    "    \n",
    "    #scatter plot our different conversion rates sampled from our distributions\n",
    "    fig, ax = plt.subplots(figsize=(8,8))\n",
    "    ax.scatter(simulated_A, simulated_B, alpha = .2);\n",
    "    ax.set_xlim(plt.ylim())\n",
    "    ax.set_xlabel(f'Site_A alpha and beta {alpha_A, beta_A}') \n",
    "    ax.set_ylabel(f'Site_B alpha and beta {alpha_B, beta_B}')\n",
    "    ax.set_title(f'B is better than A with probability {prob_B_betterthan_A*100 }%')\n",
    "    ax.plot(plt.xlim(), plt.xlim(), color = 'blue');\n",
    "    return prob_B_betterthan_A\n",
    "\n",
    "compare_AB_by_simulations(site_A_samples=x['site_A_samples'], site_B_samples=x['site_B_samples'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Translation: In our simulation, 94% of the time, site B is better than site A. We can then interpret this as a probability, meaning we can say:\n",
    "\n",
    "> \"It is 94% likely that site B is better than site A.\"\n",
    "\n",
    "**CAN FREQUENTIST DO THAT?** No, they can NOT!\n",
    "\n",
    "They can only say horribly unintelligible things like \"the p-value of 0.11 does not support the decision to reject the null hypothesis at an $\\alpha$ level of 0.05.\"\n",
    "\n",
    "Who needs that crap?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Reflection:\n",
    "\n",
    "- In our model, `conversion` is a bernoulli process: it either happens or it doesn't. The `conversion rate`, the probability that it is going to happen, is a fixed value. i.e. *p* that does not change over time.\n",
    "\n",
    "- The beta distribution gives us an **estimate of *p***, but as a distribution over a range of values, not a fixed value.\n",
    "\n",
    "- Suppose we want to put some bounds on the range where the **true** value of *p* may be found. \n",
    "\n",
    "- We call this the `credible interval` and it's largely analogous to the `confidence interval` of conventional stats."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What's the 95% credible interval of site B's conversion rate?\n",
    "\n",
    "To calculate it, we measure `the area under the curve` that contains 95% of the data, or rather `the interval under the curve` that does not contain the first or last 2.5% of the data. \n",
    "\n",
    "Note that the distribution may be skewed, so these aren't necessarily symmetrical around the distribution mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "x = np.linspace(*dist_B.ppf([.001, .999]),101)\n",
    "plt.plot(x, dist_B.pdf(x))\n",
    "plt.vlines(dist_B.ppf([.025, .975]), ymin = 0, ymax = dist_B.pdf(x).max(), linestyles='dotted')\n",
    "plt.fill_between(x, 0, dist_B.pdf(x), where = (x< dist_B.ppf(.025)) | (x > dist_B.ppf(.975) ));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "interval_size = 0.95\n",
    "tail_area = (1 - interval_size) / 2\n",
    "\n",
    "print(\"{0:0.1f}% credible interval conversion rate lower bound: {1:0.3f}, upper bound {2:0.3f}\".format(\n",
    "       interval_size *100,\n",
    "       dist_B.ppf(tail_area), \n",
    "       dist_B.ppf(1 - tail_area)))\n",
    "\n",
    "# or if you are lazier\n",
    "# dist_B.ppf([0.025, .975])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hand-On: create a function `bayes_credible_interval()`\n",
    "that computes and plots Bayesian credible interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def bayes_credible_interval(site_x_samples, interval_size = 0.95, ax=None, title=''):\n",
    "    \"\"\"compute & plot bayesian credible interval\n",
    "    Args\n",
    "    ----\n",
    "        site_x_samples (1-D np.array with shape (N,)): site-x's convertion data with 0 (miss) or 1 (convert),e.g. site_A_samples or site_B_samples\n",
    "        inerval_size (float within [0,1], default .95): the size of credible interval\n",
    "        \n",
    "    Return\n",
    "    ------\n",
    "        credible_interval: a 2-tuple (lb, ub)\n",
    "    Example\n",
    "    -------\n",
    "        fig, ax = plt.subplots(figsize=(10,10))    \n",
    "        bayes_credible_interval(site_A_samples, interval_size = 0.95, ax=ax, title='Site-A')\n",
    "        bayes_credible_interval(site_B_samples, interval_size = 0.95, ax=ax, title='Site-B')\n",
    "    \"\"\"\n",
    "\n",
    "    alpha, beta = estimate_beta_params(site_x_samples)[:2]\n",
    "    #print(f'Site_x alpha and beta {alpha, beta}')\n",
    "    dist_x = stats.beta(alpha, beta)\n",
    "\n",
    "    lb = (1-interval_size)/2 # i.e. 0.025 for interval_size = 0.95\n",
    "    ub = 1 - lb # i.e. 0.975 for interval_size = 0.95\n",
    "    \n",
    "    x = np.linspace(*dist_x.ppf([.001, .999]),101)\n",
    "    \n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(8,8))\n",
    "    ax.plot(x, dist_x.pdf(x), label=title)\n",
    "    ax.vlines(dist_x.ppf([lb, ub]), ymin = 0, ymax = dist_x.pdf(x).max(), linestyles='dotted')\n",
    "    ax.fill_between(x, 0, dist_x.pdf(x), where = (x< dist_x.ppf(lb)) | (x > dist_x.ppf(ub) ));\n",
    "    ax.set_xlabel(\"All possible values for conversion rate\")\n",
    "    ax.set_ylabel(\"PDF\")\n",
    "    ax.set_title(title+f\" Conversion rate's {interval_size *100:0.1f}% credible interval  [{dist_x.ppf(lb):0.3f},{dist_x.ppf(ub):0.3f}]\")\n",
    "    ax.legend()\n",
    "    return (dist_x.ppf(lb), dist_x.ppf(ub))\n",
    "    \n",
    "fig, ax = plt.subplots(figsize=(10,10))    \n",
    "bayes_credible_interval(site_A_samples, interval_size = 0.95, ax=ax, title='Site-A')\n",
    "bayes_credible_interval(site_B_samples, interval_size = 0.95, ax=ax, title='Site-B')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What if the difference between sites A and C is larger?\n",
    "\n",
    "Let's explore this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "x = np.load(\"samples.npz\")\n",
    "\n",
    "n = 1000\n",
    "\n",
    "site_A_samples = x['site_A_samples'][:n]\n",
    "site_C_samples = x['site_C_samples'][:n]\n",
    "\n",
    "np.mean(site_A_samples), np.mean(site_C_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(10, 4))\n",
    "\n",
    "plot_beta_from_data(site_A_samples, ax, label=\"Site A\")\n",
    "plot_beta_from_data(site_C_samples, ax, label=\"Site C\")\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "compare_AB_by_simulations(site_A_samples, site_C_samples, num_simulations = 1000_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In our simulation, 100% of the time site C is better than site A. We can then interpret this as a probability, meaning we can say:\n",
    "\n",
    "> \"It is 100% likely that site C is better than site A.\"\n",
    "\n",
    "We used 1,000 samples of each site just now. We _probably_ didn't need this much data in this case; we probably spent longer running this test than needed. Re-run the three cells above using less data. (You really only need about 300 samples of each site with this amount of difference between the sites.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What Benefits does Bayesian A/B Testing bring?\n",
    "\n",
    "In general, Bayesian A/B testing is better for these reason:\n",
    "\n",
    "1. You can say stuff like \"It is x\\% likely that site B is better than site A.\" Rather than saying \"Assuming that site A performs the same as site B, there are (1-x)\\% chance to see such data.\"\n",
    "\n",
    "2. You can stop the test early based on surprising data (in business, time=money!).\n",
    "\n",
    "3. You can has the most updated result when the test is still running."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 6. Why do we call this Bayesian A/B Testing?\n",
    "\n",
    "I haven't yet proved to you that what we did above is actually _correct_. All we've done is show that the Beta Distribution _seems_ to do what we want if we set $\\alpha$ and $\\beta$ to the number of conversions and failures, respectively. Let's work on showing _why_ this works.\n",
    "\n",
    "We can derive it by beginning with Bayes' Theorem. First, let's just recall the theorem:\n",
    "\n",
    "![](images/bayes-theorem-PHE.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Hypothesis $H$ represents the random variable that is our unknown conversion rate\n",
    "\n",
    "- Evidence $E$ is the number of conversions we've observed on the website to-date.\n",
    "\n",
    "- the denominator on the right $P(E)$ is just a normalizing term, so we'll simplify it to:\n",
    "\n",
    "$$P(H \\, | \\, E) \\propto P(E\\, | \\, H) P(H)$$\n",
    "\n",
    "\n",
    "**Baysian Thinking**: In the past we've only put `scalar values` into each part of the equation above, but now, what if we plugged `PDF equations` into each part?\n",
    "\n",
    "- Our prior $P(H)$ will be a uniform distribution initially, meaning we don't have any initial belief about what values $H$ should be -- we see all values as equally likely (we don't _have_ to do it this way, but this will work fine).  We use the $H$ here, however, because it can give a uniform distribution initially but evolve as data comes in.\n",
    "\n",
    "- Our likelihood distribution $P(E\\, | \\, H)$ is a Binomial distribution. It will tell us the likelihood of our data under various values of $H$. \n",
    "\n",
    "- the posterior distribution ($P(H \\, | \\, E)$) tells us what we actually want to know: the relative probability of each value of $H$ (i.e. the relative probability of each possible conversion rate).\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "P(H =\\Theta\\, | \\, E=y) &\\propto P(E=y \\, | \\, H=\\Theta) * P(H=\\Theta) \\\\\n",
    "P(\\Theta \\, | \\, y) &\\propto P(y \\, | \\, \\Theta) * P(\\Theta) \\\\\n",
    "P(\\Theta \\, | \\, y) &\\propto \\text{Binomial}(n, \\Theta) * \\text{Beta}(\\alpha, \\beta) \\\\\n",
    "P(\\Theta \\, | \\, y) &\\propto {n \\choose y} \\Theta^y (1-\\Theta)^{n-y} * \\dfrac{\\Theta^{\\alpha - 1} (1-\\Theta)^{\\beta - 1}}{B(\\alpha, \\beta)} \\\\\n",
    "P(\\Theta \\, | \\, y) &\\propto \\Theta^y (1-\\Theta)^{n-y} * \\Theta^{\\alpha - 1} (1-\\Theta)^{\\beta - 1} \\\\\n",
    "P(\\Theta \\, | \\, y) &\\propto \\Theta^{\\alpha + y - 1} (1-\\Theta)^{\\beta + n - y - 1} \\\\\n",
    "P(\\Theta \\, | \\, y) &= \\text{Beta}(\\alpha' = \\alpha + y, \\, \\, \\beta' = \\beta + n - y) \\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "\n",
    "All that's to say, if you multiply a Beta distribution by a Binomial distribution, out pops a *new* Beta distribution:\n",
    "\n",
    "$$\\text{Beta} \\propto \\text{Binomial} * \\text{Beta}$$\n",
    "\n",
    "This relationship, where your prior and posterior are of the same distribution family, is called a `conjugate prior`.  The Beta distribution is a `conjugate prior` of the binomial distribution. There are many more [conjugate prior relationships.](https://en.wikipedia.org/wiki/Conjugate_prior)\n",
    "\n",
    "![](images/conj_prior.png)\n",
    "\n",
    "The derivation above shows that our process for modeling conversion rates on websites is sound. What's really going on is that we've found a short-cut way of applying Bayes' theorem to update our prior beliefs. We usually make our first prior just a uniform distribution by using a Beta distribution with $\\alpha=1$ and $\\beta=1$.\n",
    "\n",
    "To recap, we model the conversion rate as a Beta distribution where:\n",
    "- $\\alpha = 1 + \\text{number of success on our website}$\n",
    "- $\\beta = 1 + \\text{number of failures on our website}$\n",
    "\n",
    "This final plot shows how we can update our belief with more-and-more data to get stronger-and-stronger beliefs of the underlying conversion rate of our website. i.e. \n",
    "\n",
    ">We iteratively update our belief with new evidence so that it approach the real (but unknown) conversion rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "x = np.load(\"samples.npz\")\n",
    "\n",
    "site_A_samples = x['site_A_samples']\n",
    "\n",
    "len(site_A_samples), np.mean(site_A_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(10, 4))\n",
    "\n",
    "num_samples = [10, 100, 1000]  # , 10000\n",
    "\n",
    "for k in num_samples:\n",
    "    samples = site_A_samples[:k]\n",
    "    plot_beta_from_data(samples, ax, label=f\"After {k} samples\")\n",
    "\n",
    "ax.set_title(\"Number of samples needed to push your BELIEF to the TRUE conversion rate 0.2\")\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hand-on: create a function `plot_samplesize_belief_truth()`\n",
    "that shows the number of samples needed to push your BELIEF to the TRUE conversion rate.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_samplesize_belief_truth(site_x_samples, num_samples = [10, 100, 1000], ax=None, true_rate=None):\n",
    "    \"\"\"Show the number of samples needed to push your BELIEF to the TRUE conversion rate\n",
    "    Args\n",
    "    ----\n",
    "        site_x_samples (1-D np.array of shape (N,)): site x's convertion data with 0 (miss) or 1 (convert)\n",
    "        num_samples: a list of integers\n",
    "        \n",
    "    Example\n",
    "    -------\n",
    "        fig, ax = plt.subplots(figsize=(10,6))\n",
    "        plot_samplesize_belief_truth(site_A_samples, num_samples = [10, 1000], ax=ax, true_rate=None)\n",
    "        plot_samplesize_belief_truth(site_B_samples, num_samples = [10, 1000], ax=ax, true_rate=None)    \n",
    "    \"\"\"\n",
    "    \n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(10, 4))\n",
    "\n",
    "    for k in num_samples:\n",
    "        samples = site_x_samples[:k]\n",
    "        plot_beta_from_data(samples, ax, label=f\"After {k} samples\")\n",
    "\n",
    "    ax.set_title(f\"Number of samples needed to push your BELIEF to the TRUE conversion rate {true_rate}\")\n",
    "    ax.legend();\n",
    "    \n",
    "    \n",
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "plot_samplesize_belief_truth(site_A_samples, num_samples = [ 1000], ax=ax, true_rate=None)\n",
    "plot_samplesize_belief_truth(site_B_samples, num_samples = [ 1000], ax=ax, true_rate=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The End ...\n",
    "\n",
    "## AB Testing: Frequentist vs Bayesian\n",
    "\n",
    "![](images/frequentist-baysian-ab-testing.png)\n",
    "[source*****](https://www.dynamicyield.com/lesson/bayesian-testing/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the benefits of  Bayesian AB Testing?\n",
    "\n",
    "![](images/bayesian-ab-testing.png)\n",
    "[source*****](https://www.dynamicyield.com/lesson/bayesian-testing/)\n",
    "\n",
    "## What is the work-flow of Bayesian AB Testing?\n",
    "![](images/flowchart-freq-bayes.png)\n",
    "[The Bayesian New Statistics*****](https://link.springer.com/article/10.3758/s13423-016-1221-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Reflection: Bayesian Thinking and Doing\n",
    "\n",
    "`Frequentist methods` were created before modern computers. Those methods lean on limits and integrals which can be done by hand and by theory. It's from those limits and integrals that they have to take the \"long run\" point of view.\n",
    "\n",
    "`Bayesian methods` still build on the foundation of `laws of probability` and the well-known `distributions`, but Bayesians take a different approach to how they interpret probability, which fits better with our needs (usually). Bayesians love to build layers of distributions one atop the other, using Bayes' theorem to string them all together. Once built, they  visualize the final distribution by repeated sampling, requiring a lot of computation.\n",
    "\n",
    ">Bayesian all is about how to iteratively keep updating your prior belief by the next piece of evidence, so that your belief is approaching the underlining truth.\n",
    "\n",
    "All scientists love data. We love data because it helps us understand the world. That's why we like the Bayesian mindset. We believe things, we collect data, and we refine our beliefs. Then we repeat that. I leave you with this final _xkcd_.\n",
    "\n",
    "<img src=\"https://imgs.xkcd.com/comics/the_difference.png\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References & Credits\n",
    "\n",
    "- Lecture notebooks by Galvanize**r** Ryan, Heather, Frank\n",
    "\n",
    "- [Why you should try the Bayesian approach of A/B testing](https://towardsdatascience.com/why-you-should-try-the-bayesian-approach-of-a-b-testing-38b8079ea33a)\n",
    "\n",
    "- [Bayesian Testing](https://www.dynamicyield.com/lesson/bayesian-testing/)\n",
    "\n",
    "- [The Bayesian New Statistics: Hypothesis testing, estimation, meta-analysis, and power analysis from a Bayesian perspective](https://link.springer.com/article/10.3758/s13423-016-1221-4)\n",
    "\n",
    "- [Bayesian A/B testing — a practical exploration with simulations](https://towardsdatascience.com/exploring-bayesian-a-b-testing-with-simulations-7500b4fc55bc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
